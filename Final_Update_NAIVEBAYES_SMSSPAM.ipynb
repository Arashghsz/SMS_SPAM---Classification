{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Arashghsz/SMS_SPAM---Classification/blob/Master/Final_Update_NAIVEBAYES_SMSSPAM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6b0edce-ccb6-4a1b-93d8-b4e7b7afe00e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d80006e0-5c6a-4444-94f9-83f874ff3ac9"
      },
      "source": [
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import string\n",
        "from nltk import pos_tag\n",
        "from nltk.stem import PorterStemmer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')"
      ],
      "id": "b6b0edce-ccb6-4a1b-93d8-b4e7b7afe00e",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-abAMyi1fP1"
      },
      "source": [
        "dataset_path = Path(\"SMSSpamCollection\")"
      ],
      "id": "9-abAMyi1fP1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9b5abeb1-d72f-46d0-a4e3-a364ae6ff606"
      },
      "source": [
        "dataSet = pd.read_csv(dataset_path, sep='\\t', header=None, names=['SMS', 'Label'])"
      ],
      "id": "9b5abeb1-d72f-46d0-a4e3-a364ae6ff606",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "05d51a06-ad5a-4ed4-9ea6-1efbe6ba976d",
        "outputId": "f22cf896-d096-4b73-c860-888b0b097d55"
      },
      "source": [
        "# Randomize the entire data set\n",
        "randomized_collection = dataSet.sample(frac=1, random_state=3)\n",
        "\n",
        "# Calculate index for split\n",
        "training_test_index = round(len(randomized_collection) * 0.7)\n",
        "\n",
        "# Training/Test split\n",
        "x_train = randomized_collection[:training_test_index].reset_index(drop=True)\n",
        "x_test = randomized_collection[training_test_index:].reset_index(drop=True)\n",
        "\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)"
      ],
      "id": "05d51a06-ad5a-4ed4-9ea6-1efbe6ba976d",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3900, 2)\n",
            "(1672, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3604b853-10b8-4d96-bdf0-3a99a01df791",
        "outputId": "e73bb3fb-b5af-40d4-9c82-f51bfa8c2e19"
      },
      "source": [
        " print(x_train['Label'].value_counts(normalize = True))\n",
        "x_test['Label'].value_counts(normalize = True)"
      ],
      "id": "3604b853-10b8-4d96-bdf0-3a99a01df791",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sorry, I'll call later                                                                                                                                                                                                              0.003333\n",
            "Ok...                                                                                                                                                                                                                               0.001795\n",
            "I cant pick the phone right now. Pls send a message                                                                                                                                                                                 0.001282\n",
            "Wen ur lovable bcums angry wid u, dnt take it seriously.. Coz being angry is d most childish n true way of showing deep affection, care n luv!.. kettoda manda... Have nice day da.                                                 0.001026\n",
            "Ok                                                                                                                                                                                                                                  0.001026\n",
            "                                                                                                                                                                                                                                      ...   \n",
            "Haf u eaten? Wat time u wan me 2 come?                                                                                                                                                                                              0.000256\n",
            "Then we wait 4 u lor... No need 2 feel bad lar...                                                                                                                                                                                   0.000256\n",
            "Good afternoon on this glorious anniversary day, my sweet J !! I hope this finds you happy and content, my Prey. I think of you and send a teasing kiss from across the sea coaxing images of fond souveniers ... You Cougar-Pen    0.000256\n",
            "We tried to contact you re our offer of New Video Phone 750 anytime any network mins HALF PRICE Rental camcorder call 08000930705 or reply for delivery Wed                                                                         0.000256\n",
            "You tell what happen dont behave like this to me. Ok no need to say                                                                                                                                                                 0.000256\n",
            "Name: Label, Length: 3692, dtype: float64\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sorry, I'll call later                                                                                                            0.010167\n",
              "I cant pick the phone right now. Pls send a message                                                                               0.004187\n",
              "Gud mrng dear hav a nice day                                                                                                      0.001794\n",
              "Just sleeping..and surfing                                                                                                        0.001794\n",
              "Ok...                                                                                                                             0.001794\n",
              "                                                                                                                                    ...   \n",
              "Check mail.i have mailed varma and kept copy to you regarding membership.take care.insha allah.                                   0.000598\n",
              "Okey doke. I'm at home, but not dressed cos laying around ill! Speak to you later bout times and stuff.                           0.000598\n",
              "Have you not finished work yet or something?                                                                                      0.000598\n",
              "You getting back any time soon?                                                                                                   0.000598\n",
              "Multiply the numbers independently and count decimal points then, for the division, push the decimal places like i showed you.    0.000598\n",
              "Name: Label, Length: 1613, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 162
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2912aecc-52e7-450c-b120-9e002be32a81"
      },
      "source": [
        "# Replace addresses (hhtp, email), numbers (plain, phone), money symbols\n",
        "x_test['SMS'] = x_test['SMS'].str.replace(r'\\b[\\w\\-.]+?@\\w+?\\.\\w{2,4}\\b',\n",
        "                                          ' ')\n",
        "x_test['SMS'] = x_test['SMS'].str.replace(r'(http[s]?\\S+)|(\\w+\\.[A-Za-z]{2,4}\\S*)',\n",
        "                                          ' ')\n",
        "x_test['SMS'] = x_test['SMS'].str.replace(r'£|\\$', ' ')    \n",
        "x_test['SMS'] = x_test['SMS'].str.replace(r'\\b(\\+\\d{1,2}\\s)?\\d?[\\-(.]?\\d{3}\\)?[\\s.-]?\\d{3}[\\s.-]?\\d{4}\\b',\n",
        "                                          ' ')    \n",
        "x_test['SMS'] = x_test['SMS'].str.replace(r'\\d+(\\.\\d+)?', ' ')\n",
        "\n",
        "# Remove punctuation, collapse all whitespace (spaces, line breaks, tabs) into a single space & eliminate any leading/trailing whitespace.\n",
        "x_test['SMS'] = x_test['SMS'].str.replace(r'[^\\w\\d\\s]', ' ')\n",
        "x_test['SMS'] = x_test['SMS'].str.replace(r'\\s+', ' ')\n",
        "x_test['SMS'] = x_test['SMS'].str.replace(r'^\\s+|\\s+?$', '')\n",
        "\n",
        "# Lowercase the entire corpus\n",
        "x_test['SMS'] = x_test['SMS'].str.lower()"
      ],
      "id": "2912aecc-52e7-450c-b120-9e002be32a81",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e51449ca-1b28-4114-8bb4-70bb0d26ae62"
      },
      "source": [
        "## removal stopwords "
      ],
      "id": "e51449ca-1b28-4114-8bb4-70bb0d26ae62"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fda51b4b-9e89-4d6e-82b1-daa59121105e"
      },
      "source": [
        "stop_words = nltk.corpus.stopwords.words('english')\n",
        "#stop_words[:10]"
      ],
      "id": "fda51b4b-9e89-4d6e-82b1-daa59121105e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ed3bedb9-a782-4242-9413-5dd290e44e00"
      },
      "source": [
        "x_test['SMS'] = x_test['SMS'].apply(lambda x: ' '.join(\n",
        "    term for term in x.split() if term not in set(stop_words))\n",
        ")"
      ],
      "id": "ed3bedb9-a782-4242-9413-5dd290e44e00",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "976fb65b-6618-4386-b2e9-cf1c999536db"
      },
      "source": [
        "## Lemmatization"
      ],
      "id": "976fb65b-6618-4386-b2e9-cf1c999536db"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "350f8c04-13e0-4ddc-8896-f6f1ac7264c2"
      },
      "source": [
        "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
        "x_test['SMS'] = x_test['SMS'].apply(lambda x: ' '.join(\n",
        "    lemmatizer.lemmatize(term, pos='v') for term in x.split())\n",
        ")"
      ],
      "id": "350f8c04-13e0-4ddc-8896-f6f1ac7264c2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "caaa8829-52dc-4c16-99d6-39e4f062e2c5"
      },
      "source": [
        "## Stemming"
      ],
      "id": "caaa8829-52dc-4c16-99d6-39e4f062e2c5"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "346c76c9-cc76-4cfb-9a18-ab449db12d3d"
      },
      "source": [
        "porter = nltk.PorterStemmer()\n",
        "x_test['SMS'] = x_test['SMS'].apply(lambda x: ' '.join(\n",
        "    porter.stem(term) for term in x.split())\n",
        ")"
      ],
      "id": "346c76c9-cc76-4cfb-9a18-ab449db12d3d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ce8e597-c93c-4c84-9d9b-0028a7ae1365"
      },
      "source": [
        "## Tokenization"
      ],
      "id": "8ce8e597-c93c-4c84-9d9b-0028a7ae1365"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "757bb3ca-47f9-475b-ad9f-e1380f2a0a84"
      },
      "source": [
        "x_test['SMS'] = x_test['SMS'].apply(lambda sms: nltk.word_tokenize(sms))"
      ],
      "id": "757bb3ca-47f9-475b-ad9f-e1380f2a0a84",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46363988-5cfa-4e5f-90ab-5d4423e2d85a"
      },
      "source": [
        "##  Feature Extraction\n",
        "### Vectorization\n"
      ],
      "id": "46363988-5cfa-4e5f-90ab-5d4423e2d85a"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43d39849-1037-493a-9e1b-b21cf201df7f"
      },
      "source": [
        "corpus = x_test['SMS'].sum()"
      ],
      "id": "43d39849-1037-493a-9e1b-b21cf201df7f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ce9a4c5-5a94-40b0-9d6d-e4678b4cb935",
        "outputId": "7de8a17c-e71d-4eaa-818e-2401a32f14cc"
      },
      "source": [
        "len(corpus)"
      ],
      "id": "6ce9a4c5-5a94-40b0-9d6d-e4678b4cb935",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1672"
            ]
          },
          "metadata": {},
          "execution_count": 170
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6abf401-6b90-4793-844f-1a3519d60570"
      },
      "source": [
        "# Transform the list to a set, to remove duplicates\n",
        "temp_set = set(corpus)\n",
        "\n",
        "# Revert to a list\n",
        "vocabulary = list(temp_set)"
      ],
      "id": "d6abf401-6b90-4793-844f-1a3519d60570",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3239a103-a6b3-4f31-9f29-ddaebf71c81d"
      },
      "source": [
        "# Create the dictionary\n",
        "len_training_set = len(x_test['SMS'])\n",
        "word_counts_per_sms = {unique_word: [0] * len_training_set for unique_word in vocabulary}\n",
        "\n",
        "for index, sms in enumerate(x_test['SMS']):\n",
        "    for word in sms:\n",
        "        word_counts_per_sms[word][index] += 1"
      ],
      "id": "3239a103-a6b3-4f31-9f29-ddaebf71c81d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1b54c502-29b8-4399-a437-076ce3766915"
      },
      "source": [
        "# Convert to dataframe\n",
        "word_counts = pd.DataFrame(word_counts_per_sms)"
      ],
      "id": "1b54c502-29b8-4399-a437-076ce3766915",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0db58c94-605a-4670-994e-a06448a87e2c"
      },
      "source": [
        "# Concatenate with the original training set\n",
        "training_set_final = pd.concat([training_set, word_counts], axis=1)\n"
      ],
      "id": "0db58c94-605a-4670-994e-a06448a87e2c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8127ded7-0add-41b2-bd5e-3555907a514a"
      },
      "source": [
        "## Calculating Constants First\n"
      ],
      "id": "8127ded7-0add-41b2-bd5e-3555907a514a"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10ca4919-b609-41e6-a916-527ec47191b0"
      },
      "source": [
        "# Filter the spam and ham dataframes\n",
        "spam_df = training_set_final[training_set_final['Label'] == 'spam'].copy()\n",
        "ham_df = training_set_final[training_set_final['Label'] == 'ham'].copy()"
      ],
      "id": "10ca4919-b609-41e6-a916-527ec47191b0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78d238c7-8a3f-4681-8775-eaca20e484ba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2018c67-7865-4e71-b824-bf342f878804"
      },
      "source": [
        "spam_df.shape,ham_df.shape"
      ],
      "id": "78d238c7-8a3f-4681-8775-eaca20e484ba",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((530, 4), (3370, 4))"
            ]
          },
          "metadata": {},
          "execution_count": 203
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60e24548-a3d2-4887-8df3-0d585f3939f3"
      },
      "source": [
        "# Calculate P(Spam) and P(Ham)\n",
        "p_spam = spam_df.shape[0] / training_set_final.shape[0]\n",
        "p_ham = ham_df.shape[0] / training_set_final.shape[0]"
      ],
      "id": "60e24548-a3d2-4887-8df3-0d585f3939f3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a99c7d56-643d-4416-b355-7c3b9edb6d29",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c56b0677-d757-430a-dbd4-9c5075e14fd1"
      },
      "source": [
        "print('p(spam) =',p_spam)\n",
        "print('p(ham) =',p_ham)"
      ],
      "id": "a99c7d56-643d-4416-b355-7c3b9edb6d29",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "p(spam) = 0.1358974358974359\n",
            "p(ham) = 0.8641025641025641\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bd13d0a2-4017-43b3-aa9b-73fa7cdbf182"
      },
      "source": [
        "# # Calculate Nspam, Nham and Nvocabulary\n",
        "# spam_words_per_message = spam_df['SMS'].apply(len)\n",
        "# n_spam = spam_words_per_message.sum()\n",
        "\n",
        "# ham_words_per_message = ham_df['SMS'].apply(len)\n",
        "# n_ham = ham_words_per_message.sum()\n",
        "\n",
        "# n_vocabulary = len(vocabulary)"
      ],
      "id": "bd13d0a2-4017-43b3-aa9b-73fa7cdbf182",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9653e39b-96cf-424d-aa19-f29182decc74",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47cf14fb-712b-4e85-9013-19f757b012f0"
      },
      "source": [
        "n_spam,n_ham,n_vocabulary"
      ],
      "id": "9653e39b-96cf-424d-aa19-f29182decc74",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7932, 27339, 5103)"
            ]
          },
          "metadata": {},
          "execution_count": 207
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0d64f14c-06ed-4a0e-96d7-9b11d0d1f1fd"
      },
      "source": [
        "# Opting for the Laplace smoothing\n",
        "alpha = 1"
      ],
      "id": "0d64f14c-06ed-4a0e-96d7-9b11d0d1f1fd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08d04c57-42bc-4c73-a9df-3869565fad5d"
      },
      "source": [
        "\n",
        "parameters_spam = {unique_word: 0 for unique_word in vocabulary}\n",
        "parameters_ham = {unique_word: 0 for unique_word in vocabulary}\n",
        "\n",
        "# calculate P(wi|Spam) and P(wi|Ham)\n",
        "for unique_word in vocabulary:\n",
        "    p_unique_word_spam = (spam_df[unique_word].sum() + alpha) / (n_spam + alpha * n_vocabulary)\n",
        "    p_unique_word_ham = (ham_df[unique_word].sum() + alpha) / (n_ham + alpha * n_vocabulary)\n",
        "    \n",
        "    # Update the calculated propabilities to the dictionaries\n",
        "    parameters_spam[unique_word] = p_unique_word_spam\n",
        "    parameters_ham[unique_word] = p_unique_word_ham"
      ],
      "id": "08d04c57-42bc-4c73-a9df-3869565fad5d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6b5338fa-b8b4-4127-bfa4-2bf965115bcb"
      },
      "source": [
        "\n",
        "def sms_classify(message):\n",
        "    '''\n",
        "    Takes in as input a new sms (w1, w2, ..., wn),\n",
        "    calculates P(Spam|w1, w2, ..., wn) and P(Ham|w1, w2, ..., wn),\n",
        "    compares them and outcomes whether the message is spam or not.\n",
        "    '''\n",
        "    \n",
        "    # Replace addresses (hhtp, email), numbers (plain, phone), money symbols\n",
        "    message = message.replace(r'\\b[\\w\\-.]+?@\\w+?\\.\\w{2,4}\\b', ' ')\n",
        "    message = message.replace(r'(http[s]?\\S+)|(\\w+\\.[A-Za-z]{2,4}\\S*)', ' ')\n",
        "    message = message.replace(r'£|\\$', ' ')    \n",
        "    message = message.replace(r'\\b(\\+\\d{1,2}\\s)?\\d?[\\-(.]?\\d{3}\\)?[\\s.-]?\\d{3}[\\s.-]?\\d{4}\\b', ' ')    \n",
        "    message = message.replace(r'\\d+(\\.\\d+)?', ' ')\n",
        "\n",
        "    # Remove punctuation, collapse all whitespace (spaces, line breaks, tabs) into a single space & eliminate any leading/trailing whitespace.\n",
        "    message = message.replace(r'[^\\w\\d\\s]', ' ')\n",
        "    message = message.replace(r'\\s+', ' ')\n",
        "    message = message.replace(r'^\\s+|\\s+?$', '')\n",
        "\n",
        "    # Lowercase the entire corpus\n",
        "    message = message.lower()\n",
        "\n",
        "    # Remove stop words    \n",
        "    terms = []\n",
        "    for term in message.split():\n",
        "        if term not in set(stop_words):\n",
        "            terms.append(term)\n",
        "            message = ' '.join(terms)\n",
        "\n",
        "    # Lemmatization\n",
        "    message = ' '.join(lemmatizer.lemmatize(term, pos='v') for term in message.split())            \n",
        "            \n",
        "    # Stemming\n",
        "    message = ' '.join(porter.stem(term) for term in message.split())  \n",
        "    \n",
        "    # Tokenization\n",
        "    message = message.split()\n",
        "    \n",
        "    p_spam_given_message = p_spam\n",
        "    p_ham_given_message = p_ham\n",
        "    \n",
        "    for word in message:\n",
        "        if word in parameters_spam:\n",
        "            p_spam_given_message *= parameters_spam[word]\n",
        "    \n",
        "        if word in parameters_ham:\n",
        "            p_ham_given_message *= parameters_ham[word]\n",
        "    \n",
        "    print('P(Spam|message):', p_spam_given_message)\n",
        "    print('P(Ham|message):', p_ham_given_message)\n",
        "\n",
        "    if p_ham_given_message > p_spam_given_message:\n",
        "        print('Label: Ham')\n",
        "    elif p_ham_given_message < p_spam_given_message:\n",
        "        print('Label: Spam')\n",
        "    else:\n",
        "        print('Equal')"
      ],
      "id": "6b5338fa-b8b4-4127-bfa4-2bf965115bcb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9aa05d85-3af7-41e8-8933-517a9ddb3446",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9d1a5ff-28dd-4218-b9d9-5b23fe421bff"
      },
      "source": [
        "sms_classify('''Hey, Sign up with this promo code and get your card for amazing\n",
        "                exchange fees abroad and £5 to spend anywhere! Promocode: D48KV7BN''')"
      ],
      "id": "9aa05d85-3af7-41e8-8933-517a9ddb3446",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "P(Spam|message): 0.1358974358974359\n",
            "P(Ham|message): 0.8641025641025641\n",
            "Label: Ham\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16defeb2-5f48-43c5-85d0-dcaa8252e4e5"
      },
      "source": [
        "# define the classify () function again, this time returning the outcomes\n",
        "def sms_classify_test_set(message):\n",
        "    '''\n",
        "    Takes in as input a new sms (w1, w2, ..., wn),\n",
        "    calculates P(Spam|w1, w2, ..., wn) and P(Ham|w1, w2, ..., wn),\n",
        "    compares them and returns the spam or ham label\n",
        "    '''\n",
        "    \n",
        "    # Replace addresses (hhtp, email), numbers (plain, phone), money symbols\n",
        "    message = message.replace(r'\\b[\\w\\-.]+?@\\w+?\\.\\w{2,4}\\b', ' ')\n",
        "    message = message.replace(r'(http[s]?\\S+)|(\\w+\\.[A-Za-z]{2,4}\\S*)', ' ')\n",
        "    message = message.replace(r'£|\\$', ' ')    \n",
        "    message = message.replace(r'\\b(\\+\\d{1,2}\\s)?\\d?[\\-(.]?\\d{3}\\)?[\\s.-]?\\d{3}[\\s.-]?\\d{4}\\b', ' ')    \n",
        "    message = message.replace(r'\\d+(\\.\\d+)?', ' ')\n",
        "\n",
        "    # Remove punctuation, collapse all whitespace (spaces, line breaks, tabs) into a single space & eliminate any leading/trailing whitespace.\n",
        "    message = message.replace(r'[^\\w\\d\\s]', ' ')\n",
        "    message = message.replace(r'\\s+', ' ')\n",
        "    message = message.replace(r'^\\s+|\\s+?$', '')\n",
        "\n",
        "    # Lowercase the entire corpus\n",
        "    message = message.lower()\n",
        "    \n",
        "    # Remove stop words    \n",
        "    terms = []\n",
        "    for term in message.split():\n",
        "        if term not in set(stop_words):\n",
        "            terms.append(term)\n",
        "            message = ' '.join(terms)\n",
        "    \n",
        "    # Lemmatization\n",
        "    message = ' '.join(lemmatizer.lemmatize(term, pos='v') for term in message.split())\n",
        "    \n",
        "    # Stemming\n",
        "    message = ' '.join(porter.stem(term) for term in message.split())\n",
        "    \n",
        "    # Tokenization\n",
        "    message = message.split()\n",
        "\n",
        "    p_spam_given_message = p_spam\n",
        "    p_ham_given_message = p_ham\n",
        "\n",
        "    for word in message:\n",
        "        if word in parameters_spam:\n",
        "            p_spam_given_message *= parameters_spam[word]\n",
        "\n",
        "        if word in parameters_ham:\n",
        "            p_ham_given_message *= parameters_ham[word]\n",
        "\n",
        "    if p_ham_given_message > p_spam_given_message:\n",
        "        return 'ham'\n",
        "    elif p_spam_given_message > p_ham_given_message:\n",
        "        return 'spam'\n",
        "    else:\n",
        "        return 'needs human classification'"
      ],
      "id": "16defeb2-5f48-43c5-85d0-dcaa8252e4e5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ae5d49f3-dbe2-470e-b403-940f9425d1b9"
      },
      "source": [
        "test_set['sms_predicted'] = test_set['SMS'].apply(sms_classify_test_set)"
      ],
      "id": "ae5d49f3-dbe2-470e-b403-940f9425d1b9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ca51491e-c235-44e1-8487-252efc3e1457",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "181a2f65-71b7-48f0-a01c-9fec09a5a08d"
      },
      "source": [
        "#accuracy\n",
        "tp = 0\n",
        "n = test_set.shape[0]\n",
        "\n",
        "for row in test_set.iterrows():\n",
        "    row = row[1]\n",
        "    if row['Label'] == row['sms_predicted']:\n",
        "        tp += 1\n",
        "\n",
        "print('TP:', tp)\n",
        "print('error:', n - tp)\n",
        "print('Accuracy:', tp / total)"
      ],
      "id": "ca51491e-c235-44e1-8487-252efc3e1457",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TP: 1455\n",
            "error: 217\n",
            "Accuracy: 0.8702153110047847\n"
          ]
        }
      ]
    }
  ]
}